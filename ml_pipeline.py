# -*- coding: utf-8 -*-
"""ML pipeline implementation with categorical features complete project in PySpark.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18uKSiPC_6TSKwQIGdOQsjP--DPgOpmbU
"""



# Install Java Development Kit for Spark
!apt-get install openjdk-8-jdk

# install PySpark with latest version
!pip install pyspark

# Set the JAVA_HOME env variable

import os

os.environ["JAVA_HOME"]="/usr/lib/jvm/java-8-openjdk-amd64"

# get current working directory
!pwd

!echo $JAVA_HOME

# mount drive

from google.colab import drive
drive.mount("/content/drive")

# import initial libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

# Create object of spark session
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName("pyspark-ml-pipeline").getOrCreate()

# Read data from csv file
df = spark.read.csv("/content/bank.csv", inferSchema=True, header=True)

df.show(5)

# Removing unwanted columns
df = df.drop(*["contact", "day", "month", "default"])
df.columns

df.dtypes

# create a list of columns
cols = df.columns
cols

# get all columns that are of string datatype
categoricalCols = [item[0] for item in df.dtypes if item[1].startswith("string")]
categoricalCols

# get all columns that are of integer datatype
numericalCols = [item[0] for item in df.dtypes if item[1].startswith("int")]
numericalCols

# get basic statistics of the numerical columns
df.select(numericalCols).describe().toPandas()

# checking correlation between numerical columns

numerical_data = df.select(numericalCols).toPandas()
numerical_data.corr()

from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler

stages = [] # to hold the different stages of the data transformation pipeline.

# StringIndexer: Converts categorical values into numerical indices.
# OneHotEncoder: Converts indexed values into a one-hot encoded vector.

for categoricalCol in categoricalCols:
    stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol + 'Index')
    encoder = OneHotEncoder(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + "classVec"])
    stages += [stringIndexer, encoder]

# Convert the label column (deposit) into numerical indices.

label_stringIdx = StringIndexer(inputCol='deposit', outputCol='label')
stages += [label_stringIdx]

# assemblerInputs: Combines the one-hot encoded vectors of the categorical columns and the numeric columns.
# VectorAssembler: Combines all feature columns into a single feature vector column named features

assemblerInputs = [c + "classVec" for c in categoricalCols] + numericalCols
assembler = VectorAssembler(inputCols=assemblerInputs, outputCol="features")
stages += [assembler]

# import pipeline
from pyspark.ml import Pipeline

# Create and set up the pipeline
pipeline = Pipeline(stages=stages)

# Fit the pipeline to the DataFrame
pipelineModel = pipeline.fit(df)

# Applying the fitted pipeline model to the DataFrame df to transform it
df = pipelineModel.transform(df)

# Select the columns label, features, and the original columns from cols to include in the final DataFrame.
selectedCols = ["label", "features"] + cols

# Print the schema of the transformed DataFrame to verify the structure and data types of the selected columns.
df = df.select(selectedCols)
df.printSchema()

# check first five row instances
df.toPandas().head()

# Splitting data to train and test set
train_df, test_df = df.randomSplit([0.8, 0.2], seed=2024)

# get length of train and test data
print("Training Dataset Count: " + str(train_df.count()))
print("Test Dataset Count: " + str(test_df.count()))

# import Logistic regression
from pyspark.ml.classification import LogisticRegression

# Initialize the Logistic Regression Model
lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=10)
lrModel = lr.fit(train_df)

# Retrieve and Display Model Summary
lr_summary=lrModel.summary

# Overall accuracy of the classification model
lr_summary.accuracy

# Area under ROC
lr_summary.areaUnderROC

# Precision of both classes
print(lr_summary.precisionByLabel)

# Recall of both classes
print(lr_summary.recallByLabel)

beta = np.sort(lrModel.coefficients)
plt.plot(beta)
plt.ylabel('Beta Coefficients')
plt.show()

trainingSummary = lrModel.summary
roc = trainingSummary.roc.toPandas()
plt.plot(roc['FPR'],roc['TPR'])
plt.ylabel('False Positive Rate')
plt.xlabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
print('Training set areaUnderROC: ' + str(trainingSummary.areaUnderROC))

pr = trainingSummary.pr.toPandas()
plt.plot(pr['recall'],pr['precision'])
plt.ylabel('Precision')
plt.xlabel('Recall')
plt.show()

predictions = lrModel.transform(test_df)
predictions.select('label','rawPrediction','probability','prediction').toPandas().head(20)
predictions.select('label','prediction').toPandas().head(20)

# Evaluate our Logistic Regression model.
from pyspark.ml.evaluation import BinaryClassificationEvaluator
evaluator = BinaryClassificationEvaluator()
print('Test Area Under ROC', evaluator.evaluate(predictions))

from pyspark.ml.tuning import ParamGridBuilder, CrossValidator

# Create ParamGrid for Cross Validation
paramGrid = (ParamGridBuilder()
             .addGrid(lr.regParam, [0.01, 0.5, 2.0])
             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])
             .addGrid(lr.maxIter, [1, 5, 10])
             .build())

cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)

cvModel = cv.fit(train_df)
predictions = cvModel.transform(test_df)
print('Test Area Under ROC', evaluator.evaluate(predictions))

evaluator.getMetricName()

# Decision Tree Classifier
from pyspark.ml.classification import DecisionTreeClassifier

dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)
dtModel = dt.fit(train_df)

predictions = dtModel.transform(test_df)
predictions.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)

# Evaluate our Decision Tree model.
evaluator = BinaryClassificationEvaluator()
print("Test Area Under ROC: " + str(evaluator.evaluate(predictions, {evaluator.metricName: "areaUnderROC"})))

# Random Forest Classifier
from pyspark.ml.classification import RandomForestClassifier
rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')
rfModel = rf.fit(train_df)
predictions = rfModel.transform(test_df)
predictions.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)

# Evaluate our Decision Tree model.
evaluator = BinaryClassificationEvaluator()
print("Test Area Under ROC: " + str(evaluator.evaluate(predictions, {evaluator.metricName: "areaUnderROC"})))

# Gradient-Boosted Tree Classifier
from pyspark.ml.classification import GBTClassifier
gbt = GBTClassifier(maxIter=10)
gbtModel = gbt.fit(train_df)
predictions = gbtModel.transform(test_df)
predictions.select('age', 'job', 'label', 'rawPrediction', 'prediction', 'probability').show(10)

# Evaluate our Gradient-Boosted Tree Classifier.
evaluator = BinaryClassificationEvaluator()
print("Test Area Under ROC: " + str(evaluator.evaluate(predictions, {evaluator.metricName: "areaUnderROC"})))

print(gbt.explainParams())

from pyspark.ml.tuning import ParamGridBuilder, CrossValidator

paramGrid = (ParamGridBuilder()
             .addGrid(gbt.maxDepth, [2, 4, 6])
             .addGrid(gbt.maxBins, [20, 60])
             .addGrid(gbt.maxIter, [10, 20])
             .build())

cv = CrossValidator(estimator=gbt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)

# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!
cvModel = cv.fit(train_df)
predictions = cvModel.transform(test_df)

evaluator.evaluate(predictions)

